{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "from sklearn.metrics import roc_curve, roc_auc_score, precision_recall_curve, auc, f1_score, balanced_accuracy_score\n",
    "\n",
    "from tsfresh import extract_features, select_features\n",
    "from tsfresh.utilities.dataframe_functions import impute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to extract the performance metrics\n",
    "def performance_metrics(y_test,y_pred):\n",
    "    fpr, tpr, thresh = roc_curve(y_test, y_pred)\n",
    "    roc_auc = round(roc_auc_score(y_test, y_pred),4)\n",
    "\n",
    "    #calculate optimal roc auc threshold\n",
    "    optimal_idx = np.argmax(tpr - fpr)\n",
    "    optimal_threshold = thresh[optimal_idx]\n",
    "    y_optimal = y_pred>optimal_threshold\n",
    "\n",
    "    #compute f1 score, precision recall AUC, balanced accuracy\n",
    "    precision, recall, _ = precision_recall_curve(y_test, y_pred)\n",
    "    pr_auc = auc(recall, precision)\n",
    "\n",
    "    f1 = f1_score(y_test, y_optimal)\n",
    "    balanced_accuracy =balanced_accuracy_score(y_test, y_optimal)\n",
    "    return f1, pr_auc, balanced_accuracy, roc_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the data\n",
    "df_train = pd.read_csv('../../data/ptbdb_train.csv', header=None)\n",
    "df_test = pd.read_csv('../../data/ptbdb_test.csv', header=None)\n",
    "\n",
    "# Separate last column as target for train data\n",
    "data_matrix_train = df_train.values\n",
    "y_train = data_matrix_train[:,-1]\n",
    "X_train = data_matrix_train[:,0:-1]\n",
    "\n",
    "# Separate last column as target for test data\n",
    "data_matrix_test = df_test.values\n",
    "y_test = data_matrix_test[:,-1]\n",
    "X_test = data_matrix_test[:,0:-1]\n",
    "\n",
    "print('Train data shape:', X_train.shape)\n",
    "print('Test data shape:', X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seed for reproducibility\n",
    "random_seed = 13\n",
    "np.random.seed(random_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task (1)\n",
    "\n",
    "# Train random forest classifier\n",
    "rf = RandomForestClassifier(n_estimators=100, random_state=random_seed)\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "# Train MLP classifier\n",
    "mlp = MLPClassifier(hidden_layer_sizes=(100,100), random_state=random_seed)\n",
    "mlp.fit(X_train, y_train)\n",
    "\n",
    "# Train kNN classifier\n",
    "knn = KNeighborsClassifier(n_neighbors=5)\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "# Train naive bayes classifier\n",
    "nb = GaussianNB()\n",
    "nb.fit(X_train, y_train)\n",
    "\n",
    "# Predict probabilities for each classifier\n",
    "y_pred_rf = rf.predict_proba(X_test)[:,1]\n",
    "y_pred_mlp = mlp.predict_proba(X_test)[:,1]\n",
    "y_pred_knn = knn.predict_proba(X_test)[:,1]\n",
    "y_pred_nb = nb.predict_proba(X_test)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [rf, mlp, knn, nb]\n",
    "y_preds = [y_pred_rf, y_pred_mlp, y_pred_knn, y_pred_nb]\n",
    "\n",
    "for model, y_pred in zip(models, y_preds):\n",
    "    f1, pr_auc, balanced_accuracy, roc_auc = performance_metrics(y_test, y_pred)\n",
    "    \n",
    "    print(f'Model: {model.__class__.__name__}')\n",
    "    print(f'F1 score: {f1:.4f}')\n",
    "    print(f'PR AUC: {pr_auc:.4f}')\n",
    "    print(f'Balanced accuracy: {balanced_accuracy:.4f}')\n",
    "    print(f'ROC AUC: {roc_auc:.4f}')\n",
    "    print('------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate ROC-AUC for each classifier\n",
    "roc_auc_rf = roc_auc_score(y_test, y_pred_rf)\n",
    "roc_auc_mlp = roc_auc_score(y_test, y_pred_mlp)\n",
    "roc_auc_knn = roc_auc_score(y_test, y_pred_knn)\n",
    "roc_auc_nb = roc_auc_score(y_test, y_pred_nb)\n",
    "\n",
    "#Calculate ROC curves for each classifier\n",
    "fpr_rf, tpr_rf, _ = roc_curve(y_test, y_pred_rf)\n",
    "fpr_mlp, tpr_mlp, _ = roc_curve(y_test, y_pred_mlp)\n",
    "fpr_knn, tpr_knn, _ = roc_curve(y_test, y_pred_knn)\n",
    "fpr_nb, tpr_nb, _ = roc_curve(y_test, y_pred_nb)\n",
    "\n",
    "#plot ROC curves\n",
    "plt.figure()\n",
    "plt.plot(fpr_rf, tpr_rf, label='Random Forest (area = %0.4f)' % roc_auc_rf)\n",
    "plt.plot(fpr_mlp, tpr_mlp, label='MLP (area = %0.4f)' % roc_auc_mlp)\n",
    "plt.plot(fpr_knn, tpr_knn, label='kNN (area = %0.4f)' % roc_auc_knn)\n",
    "plt.plot(fpr_nb, tpr_nb, label='Naive Bayes (area = %0.4f)' % roc_auc_nb)\n",
    "plt.plot([0, 1], [0, 1],'r--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Task (2): Add features to time-series\n",
    "\n",
    "# Create a time-series dataframe with train dataset\n",
    "df_train = pd.read_csv('ptbdb_train.csv', header=None)\n",
    "X_train = df_train.iloc[:, :-1]\n",
    "y_train = df_train.iloc[:, -1]\n",
    "melted_df = X_train.melt(var_name='time', value_name='values')\n",
    "melted_df['id'] = melted_df.groupby('time').cumcount()\n",
    "timeseries = melted_df[['id', 'time', 'values']]\n",
    "\n",
    "y = pd.DataFrame({'id': range(len(y_train)), 'lbl': y_train})\n",
    "y_series = y['lbl']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extracted_features = extract_features(timeseries, column_id=\"id\", column_sort=\"time\")\n",
    "print('Extracted_features shape:', extracted_features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter features by importance\n",
    "impute(extracted_features)\n",
    "features_filtered = select_features(extracted_features, y_series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train_features is features_filtered concatenated to X_train\n",
    "X_train_features = pd.concat([X_train, features_filtered], axis=1)\n",
    "X_train_features.columns = range(X_train_features.shape[1])\n",
    "y_train_features = y_train\n",
    "\n",
    "print(X_train_features.shape, y_train_features.shape)\n",
    "\n",
    "#normalize X_test_features by column with minmax\n",
    "for column in X_train_features.columns:\n",
    "    X_train_features[column] = (X_train_features[column] - X_train_features[column].min()) / (X_train_features[column].max() - X_train_features[column].min() + 1e-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train random forest classifier\n",
    "rf2 = RandomForestClassifier(n_estimators=100, random_state=random_seed)\n",
    "rf2.fit(X_train_features, y_train_features)\n",
    "\n",
    "#train MLP classifier\n",
    "mlp2 = MLPClassifier(hidden_layer_sizes=(100,100), random_state=random_seed)\n",
    "mlp2.fit(X_train_features, y_train_features)\n",
    "\n",
    "#train kNN classifier\n",
    "knn2 = KNeighborsClassifier(n_neighbors=5)\n",
    "knn2.fit(X_train_features, y_train_features)\n",
    "\n",
    "#train naive bayes classifier\n",
    "nb2 = GaussianNB()\n",
    "nb2.fit(X_train_features, y_train_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a time-series dataframe with test dataset\n",
    "\n",
    "df_test = pd.read_csv('ptbdb_test.csv', header=None)\n",
    "X_test = df_test.iloc[:, :-1]\n",
    "y_test = df_test.iloc[:, -1]\n",
    "melted_df = X_test.melt(var_name='time', value_name='values')\n",
    "melted_df['id'] = melted_df.groupby('time').cumcount()\n",
    "test_timeseries = melted_df[['id', 'time', 'values']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extracted_features_test = extract_features(test_timeseries, column_id=\"id\", column_sort=\"time\")\n",
    "test_features_filtered = extracted_features_test.filter(items=features_filtered.columns)\n",
    "impute(test_features_filtered) # Impute nan values\n",
    "print('Test features shape:', test_features_filtered.shape)\n",
    "\n",
    "X_test_features = pd.concat([X_test, test_features_filtered], axis=1)\n",
    "X_test_features.columns = range(X_test_features.shape[1])\n",
    "\n",
    "#normalize X_test_features by column with minmax\n",
    "for column in X_test_features.columns:\n",
    "    X_test_features[column] = (X_test_features[column] - X_test_features[column].min()) / (X_test_features[column].max() - X_test_features[column].min() + 1e-6)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict probabilities for each classifier\n",
    "y_pred_rf = rf2.predict_proba(X_test_features.values)[:,1]\n",
    "y_pred_mlp = mlp2.predict_proba(X_test_features.values)[:,1]\n",
    "y_pred_knn = knn2.predict_proba(X_test_features.values)[:,1]\n",
    "y_pred_nb = nb2.predict_proba(X_test_features.values)[:,1]\n",
    "\n",
    "models = [rf2, mlp2, knn2, nb2]\n",
    "y_preds = [y_pred_rf, y_pred_mlp, y_pred_knn, y_pred_nb]\n",
    "\n",
    "for model, y_pred in zip(models, y_preds):\n",
    "    f1, pr_auc, balanced_accuracy, roc_auc = performance_metrics(y_test, y_pred)\n",
    "    \n",
    "    print(f'Model: {model.__class__.__name__}')\n",
    "    print(f'F1 score: {f1:.4f}')\n",
    "    print(f'PR AUC: {pr_auc:.4f}')\n",
    "    print(f'Balanced accuracy: {balanced_accuracy:.4f}')\n",
    "    print(f'ROC AUC: {roc_auc:.4f}')\n",
    "    print('------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate ROC-AUC for each classifier\n",
    "roc_auc_rf = roc_auc_score(y_test, y_pred_rf)\n",
    "roc_auc_mlp = roc_auc_score(y_test, y_pred_mlp)\n",
    "roc_auc_knn = roc_auc_score(y_test, y_pred_knn)\n",
    "roc_auc_nb = roc_auc_score(y_test, y_pred_nb)\n",
    "\n",
    "#Calculate ROC curves for each classifier\n",
    "fpr_rf, tpr_rf, _ = roc_curve(y_test, y_pred_rf)\n",
    "fpr_mlp, tpr_mlp, _ = roc_curve(y_test, y_pred_mlp)\n",
    "fpr_knn, tpr_knn, _ = roc_curve(y_test, y_pred_knn)\n",
    "fpr_nb, tpr_nb, _ = roc_curve(y_test, y_pred_nb)\n",
    "\n",
    "#plot ROC curves\n",
    "plt.figure()\n",
    "plt.plot(fpr_rf, tpr_rf, label='Random Forest (area = %0.4f)' % roc_auc_rf)\n",
    "plt.plot(fpr_mlp, tpr_mlp, label='MLP (area = %0.4f)' % roc_auc_mlp)\n",
    "plt.plot(fpr_knn, tpr_knn, label='kNN (area = %0.4f)' % roc_auc_knn)\n",
    "plt.plot(fpr_nb, tpr_nb, label='Naive Bayes (area = %0.4f)' % roc_auc_nb)\n",
    "plt.plot([0, 1], [0, 1],'r--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ecg-dl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
